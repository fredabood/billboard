{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tutorials**\n",
    "\n",
    "https://dluo.me/s3databoto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import boto3\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bucket(category, chart=None):\n",
    "    \n",
    "    s3 = boto3.resource('s3')\n",
    "    resource = boto3.resource('s3') # high-level object-oriented API\n",
    "    \n",
    "    bucket=f\"billboard.charts.{category.replace(' ','-')}\"\n",
    "    if chart:\n",
    "        bucket = bucket + f'.{chart}'\n",
    "    \n",
    "    try:\n",
    "        bucket = s3.create_bucket(Bucket=bucket, CreateBucketConfiguration={'LocationConstraint': 'us-west-2'})\n",
    "    except:\n",
    "        bucket = resource.Bucket(bucket)\n",
    "        \n",
    "    return bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_next_date(date):\n",
    "\n",
    "    if date > 0:\n",
    "\n",
    "        # Pull year, month, day from string\n",
    "        day = int(date[6:8])\n",
    "        month = int(date[4:6])\n",
    "        year = int(date[:4])\n",
    "\n",
    "        date = datetime(year=year,month=month,day=day) + timedelta(1)\n",
    "\n",
    "    else:\n",
    "\n",
    "        date = datetime(1958,8,4)\n",
    "\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_html(chart, bucket, date):\n",
    "    \n",
    "    '''\n",
    "    Read webpage to BeautifulSoup from internet.\n",
    "    '''\n",
    "    # Generate URL to scrape\n",
    "    url = f\"https://www.billboard.com/charts/{chart}\"\n",
    "    if date>0:\n",
    "        url = url + f\"/{date.strftime('%Y-%m-%d')}\"\n",
    "    \n",
    "    # Read webpage, Convert to text, Convert to soup\n",
    "    r  = requests.get(url)\n",
    "    data = r.text\n",
    "    soup = BeautifulSoup(data, 'html.parser')\n",
    "    \n",
    "    '''\n",
    "    Sending BeautifulSoup to S3 as a HTML file.\n",
    "    '''\n",
    "    # Save webpage to local .html file named for date\n",
    "    if date>0:\n",
    "        filename=f\"{chart}_{date.strftime('%Y%m%d')}.html\"\n",
    "    else:\n",
    "        filename=f\"{chart}_{datetime.now().strftime('%Y%m%d')}.html\"\n",
    "    \n",
    "    f = open(filename,'w')\n",
    "    f.write(str(soup))\n",
    "    \n",
    "    # Upload .txt file to S3\n",
    "    bucket.upload_file(filename, Key=filename)\n",
    "    \n",
    "    # Delete local .txt file\n",
    "    os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    '''\n",
    "    Webpage > HTML\n",
    "    '''\n",
    "\n",
    "    s3 = boto3.resource('s3')\n",
    "    resource = boto3.resource('s3') # high-level object-oriented API\n",
    "    \n",
    "    bucket = 'billboard-charts-html'\n",
    "    bucket = resource.Bucket(bucket)\n",
    "    \n",
    "    with open('charts.json') as log:\n",
    "        charts = json.load(log)\n",
    "    \n",
    "    # Save webpages to HTML files on S3 bucket\n",
    "    for category in charts:\n",
    "        for chart in charts[category]:\n",
    "    \n",
    "            date = charts[category][chart] \n",
    "            \n",
    "            if date > 0:\n",
    "\n",
    "                date = find_next_date(date)\n",
    "\n",
    "                while date <= datetime.now():\n",
    "                    save_html(chart, date, bucket)\n",
    "                    charts[category][chart] = date.strftime('%Y%m%d')\n",
    "                    date += timedelta(1)\n",
    "                    \n",
    "                    with open('charts.json', 'w') as log:\n",
    "                        json.dump(charts, log)\n",
    "                       \n",
    "            else:\n",
    "\n",
    "                save_html(chart=chart, bucket=bucket, date=date)\n",
    "                charts[category][chart] = datetime.now().strftime('%Y%m%d')\n",
    "                    \n",
    "                with open('charts.json', 'w') as log:\n",
    "                    json.dump(charts, log)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     '''\n",
    "#     HTML > CSV\n",
    "#     '''\n",
    "    \n",
    "#     # Declare S3 bucket & logfile location\n",
    "#     bucket = resource.Bucket('billboard-data') #subsitute this for your s3 bucket name.\n",
    "#     log_file = os.getcwd() + '/logs/parse_html_log.txt'\n",
    "    \n",
    "#     # Convert HTML files to CSV and push to new S3 bucket\n",
    "#     date = find_next_date(data_log_file)\n",
    "#     while date <= datetime.now():\n",
    "#         parse_html(date, bucket, log_file)\n",
    "#         date += timedelta(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_html(chart, date, bucket):\n",
    "    \n",
    "    html_file = \"{chart}_{date}.html\".format(chart=chart, date=date.strftime('%Y%m%d'))\n",
    "    \n",
    "    obj = client.get_object(Bucket=bucket, Key=html_file)\n",
    "    \n",
    "    page = urllib2.urlopen(obj['Body'])\n",
    "    soup = BeautifulSoup(page.read(), 'html.parser')\n",
    "    \n",
    "#     articles = soup.findAll('article')\n",
    "    \n",
    "#     lst = []\n",
    "\n",
    "#     for row in range(0,len(articles)-1):\n",
    "\n",
    "#         if str(articles[row].findAll('span', class_='chart-row__current-week')) == '[]':\n",
    "#             current_week_rank = None\n",
    "#         else:\n",
    "#             current_week_rank = str(articles[row].findAll('span', class_='chart-row__current-week')).split('>')[1].split('<')[0]\n",
    "\n",
    "#         if str(articles[row].findAll('h2',class_='chart-row__song')) == '[]':\n",
    "#             song_name = None\n",
    "#         else:\n",
    "#             song_name = str(articles[row].findAll('h2',class_='chart-row__song')).split('>')[1].split('<')[0]\n",
    "\n",
    "#         if str(articles[row].findAll('a',class_='chart-row__artist')) == '[]':\n",
    "#             artist_name = str(articles[row].findAll('span',class_='chart-row__artist'))\n",
    "#         else:\n",
    "#             artist_name = str(articles[row].findAll('a',class_='chart-row__artist'))\n",
    "\n",
    "#         dct = {\n",
    "#             'week_of': str(soup.findAll('time')).split('>')[1].split('<')[0],\n",
    "#             'current_week_rank': current_week_rank,\n",
    "#             'song_name': song_name,\n",
    "#             'artist_name': artist_name\n",
    "#         }\n",
    "\n",
    "#         if len(articles[row].findAll('span',class_='chart-row__value')) > 0:\n",
    "#             dct['last_week_rank'] = str(articles[row].findAll('span',class_='chart-row__value')[0]).split('>')[1].split('<')[0]\n",
    "#             dct['peak_position'] = str(articles[row].findAll('span', class_='chart-row__value')[1]).split('>')[1].split('<')[0]\n",
    "#             dct['weeks_on_chart'] = str(articles[row].findAll('span',class_='chart-row__value')[2]).split('>')[1].split('<')[0]\n",
    "\n",
    "#         lst.append(dct)\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(lst)\n",
    "    mask = df['current_week_rank'].astype(float).notna()\n",
    "    df = df[mask]\n",
    "\n",
    "    artists = []\n",
    "\n",
    "    for x in df['artist_name']:\n",
    "        artists.append(x.split('\\n')[1])\n",
    "\n",
    "    df['artist_name'] = pd.Series(artists)\n",
    "    \n",
    "    df['week_of'] = pd.to_datetime(df['week_of'])\n",
    "    \n",
    "\n",
    "    '''\n",
    "    Sending DataFrame to S3 as a CSV file.\n",
    "    '''\n",
    "               \n",
    "    filename = '{chart}_{date}.csv'.format(chart=chart, date=date.strftime('%Y%m%d'))\n",
    "    # Write DataFrame to local CSV named for date\n",
    "    df.to_csv(filename, index=False)\n",
    "    \n",
    "    # Upload CSV file to S3\n",
    "    bucket.upload_file(filename, Key=filename)\n",
    "    \n",
    "    # Delete local .txt file\n",
    "    os.remove(filename)\n",
    "    \n",
    "    # Write filename to logfile to mark successful page save\n",
    "    logfile='{chart}_parse_html_log.txt'.format(chart=chart)\n",
    "    f = open(log_file,'w')\n",
    "    f.write(str(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(filename, header=False, mode='a', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
